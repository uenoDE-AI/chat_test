# app.py
import streamlit as st
import uuid, datetime, asyncio, json, pathlib
import aiosqlite
from openai import OpenAI


# -------------------- APIã‚­ãƒ¼ã‚’ JSON ã‹ã‚‰èª­ã‚€ --------------------
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œã‚‹
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# -------------------- SQLite è¨­å®š -------------------------------
DB_PATH = "chat.db"

async def init_db():
    """å­˜åœ¨ã—ãªã‘ã‚Œã°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("""
        CREATE TABLE IF NOT EXISTS messages(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            conversation_id TEXT,
            role TEXT,
            content TEXT,
            ts TEXT,
            metadata TEXT
        )
        """)
        await db.commit()

async def save_message(cid: str, role: str, content: str):
    """1 ç™ºè¨€ã‚’ SQLite ã« INSERT"""
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("""
        INSERT INTO messages(conversation_id, role, content, ts, metadata)
        VALUES (?,?,?,?,?)
        """, (cid, role, content,
              datetime.datetime.utcnow().isoformat(),
              "{}"))
        await db.commit()

asyncio.run(init_db())          # ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æº–å‚™


# -------------------- æ–°: ä¼šè©±è¦ç´„æ©Ÿèƒ½ -------------------------------
SUMMARY_MODEL = "gpt-4o-mini"
MAX_MSG_FOR_SUMMARY = 30           # è² è·è»½æ¸›ã®ãŸã‚ç›´è¿‘ N ä»¶ã®ã¿è¦ç´„

async def generate_summary():
    """æœ€æ–°ã®ä¼šè©±ã‚’è¦ç´„ã—ã¦ st.session_state.summary ã«æ ¼ç´"""
    history = st.session_state.messages[-MAX_MSG_FOR_SUMMARY:]
    history_txt = "\n".join([f"{m['role']}: {m['content']}" for m in history])

    prompt = [
        {"role": "system",
         "content": "ã‚ãªãŸã¯å„ªç§€ãªè¦ç´„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ¬¡ã®ä¼šè©±ã‚’èª­ã‚“ã§ã€æ—¥æœ¬èªã§3ã€œ5è¡Œã«ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": history_txt}
    ]

    res = client.chat.completions.create(
        model=SUMMARY_MODEL,
        messages=prompt
    )
    st.session_state.summary = res.choices[0].message.content.strip()


# -------------------- Streamlit UI ------------------------------
st.set_page_config(
    page_title="ChatAPP with SQLite", 
    page_icon="ğŸ’¬"
    )
st.title("ChatAPP_test")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "awaiting_reply" not in st.session_state:
    st.session_state.awaiting_reply = False
if "cid" not in st.session_state:
    st.session_state.cid = str(uuid.uuid4())    # ãƒ–ãƒ©ã‚¦ã‚¶ã”ã¨ã«å›ºæœ‰ ID
if "summary" not in st.session_state:
    st.session_state.summary = "ã¾ã è¦ç´„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

cid = st.session_state.cid



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒšãƒ¼ã‚¸é¸æŠ(ä»»æ„)ï¼‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ç´„
with st.sidebar:
    st.subheader("ğŸ“ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ç´„")
    st.markdown(st.session_state.get("summary", "ã¾ã è¦ç´„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã¯ 1 åˆ—ã ã‘ã«
chat_col = st.container()          # å³åˆ—(summary_col) ã‚’å‰Šé™¤

prompt = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ã­")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ãƒãƒ£ãƒƒãƒˆæç”»ãƒ»è¿”ä¿¡ã‚¹ãƒˆãƒªãƒ¼ãƒ 
with chat_col:
    # ã“ã‚Œã¾ã§ã®ä¼šè©±
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆè¿”ä¿¡ï¼ˆå…ƒã‚³ãƒ¼ãƒ‰ã‚’ã»ã¼ãã®ã¾ã¾ï¼‰
    if st.session_state.awaiting_reply:
        full_reply = ""
        with st.chat_message("assistant"):
            with st.spinner("è€ƒãˆä¸­..."):
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=st.session_state.messages,
                    stream=True,
                )
                placeholder = st.empty()
                for chunk in response:
                    content = chunk.choices[0].delta.content or ""
                    full_reply += content
                    placeholder.markdown(full_reply + "â–")
                placeholder.markdown(full_reply)

        # DB ä¿å­˜ & è¦ç´„ç”Ÿæˆ
        st.session_state.messages.append(
            {"role": "assistant", "content": full_reply}
        )
        asyncio.run(save_message(cid, "assistant", full_reply))
        asyncio.run(generate_summary())

        st.session_state.awaiting_reply = False
        st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒã‚ã£ãŸã‚‰é€ä¿¡å‡¦ç†
if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    asyncio.run(save_message(cid, "user", prompt))
    st.session_state.awaiting_reply = True
    st.rerun()